# Задание

## Этап 1: Разбор JS*N-файла

Выделение вопросов и ответов

1.	Из JSON-структуры извлекаются:

*   Вопросы.
*	Возможные ответы 
*	Связи между узлами

2.	Формирование логической последовательности:

*	Ответы группируются по вопросам.
*	Например, если вопрос 1 имеет три варианта ответа (ответ 1, ответ 2, ответ 3), создаются группы 1.1, 1.2, 1.3.
*	Аналогично для других вопросов:

    Вопрос 2 → Ответы (2.1, 2.2, 2.3 и т. д.).
    Вопрос 3 → Ответы (3.1, 3.2 и т. д.).

*	Сохраняем последовательность ответов для генерации MP3.

## Этап 2: Генерация аудио (TTS)

1.	Преобразование текста в речь с помощью TTS (Text-to-Speech).
2.	V2 - Выбор эмоции для озвучки (лояльный, злой, нейтральный и т. д.).
3.	Создание и сохранение MP3-файлов в хранилище.
4.	Добавляем к новому json последовательность ответов и название MP3: [{ответ_1: «path_mp3», …, {ответ_n: «path_mp3»,]

## Этап 3: Работа тренажера на стороне пользователя

Последовательность действий

1.	Пользователь выбирает эмоцию (кнопкой).
2.	Ожидает генерации TTS 
3.	Получает первый вопрос:
*	Вопрос отображается на экране. (Менеджер читает вопрос)

4.	Система выбирает один из ответов из js*n.
5.	Воспроизводит MP3 (на стороне браузера).
6.	Пользователь нужный вариант ответа (нажимает кнопку с ответом), и система переходит к следующему вопросу.
7.	Процесс повторяется до завершения скрипта.
 
## Этап 4: Логирование ответов

Что логируется

*	Выбранный системой ответ (чтобы не тратить время на транскрибацию).
*	UUID следующего узла (для точного отслеживания хода диалога).
*	Выбранная эмоция.
*	Транскрибация аудио-ответов пользователя и запись текста ответа в поле «ответ» в json и сохранение его там
*	Сохрание json уже текстового формата ответов и вопросов 

## Этап 5: Сохранение и отправка записи

1.	Аудио файл с ответом на вопрос сохраняется во временное хранилище.
2.	Аудио файл транскрибируется в текст 
3.	Удалить временный аудио файл
4.	Транскрибирпованный текст записывается в json по ключу «ответ пользователя»
5.	Все json с ответами-вопросами сохраняются в список 
6.	Список с json передается в LLM для оценки качества (параметры проверки передавать в промт заранее)

## Итоговая схема работы
1.	Разбор JSON → выделение вопросов и ответов.
2.	Генерация TTS с учетом выбранной эмоции.
3.	Выдача вопросов, логирование и отображение истории диалога.
4.	Логирование выбранных системой ответов.
5.	Транскрибация и запись в json

# Недочеты

1.  Не реализовано изменение голоса по эмоциям
2.  Оценка аудио с помощью LLM

# Установка пакетов

*   bash -i installation.txt 

В installation.txt находится:

`pip install coqui-tts`

`pip install openai-whisper`

`pip install gradio`

`pip install python-Levenshtein`

`pip install python-json-logger`

`pip install pydub`