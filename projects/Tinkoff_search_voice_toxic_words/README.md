# Задача

Разработать/доработать контурную LLM, которая выявляет в диалогах (текстовых) токсичные фразы (негативный оттенок, оскорбления, бранные слова), а также признаки перебивания.

# Действия:

1. Определиться с входным форматом данных.
2. Выгрузить из различных чатов в телеграм диалоги и написать скрипт для преобразования телеграм диалогов в выбранный формат
3. Посмотреть готовые модели  и датасеты на HuggingFace по ключевому слову toxic.
4. Выбрать модель. Понять нужно ли её дообучать? Выбрать метод обучения. Если надо дообучить.
5. Запустить модель для инференса (квантование, шардинг) на CPU.
6. Проверить модель на данных из телеграм
7. Предложить варианты оптимизации.
8. Параллельно держим в голове, как определить перебивания в текстовых диалогах, высказываем предположения, проверяем предположения.
9. Прикрутить внешний словарь токсичных слов, что пользователь считает токсичностью. Например, что не этично в рамках культурных ценностей компании или отдельные слова, фразы.